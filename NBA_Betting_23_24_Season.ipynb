{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode selenium webdriver_manager\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install chromium-driver -y\n",
        "!apt-get install chromium-browser\n",
        "!apt-get install -yq chromium-chromedriver\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%reload_ext autoreload"
      ],
      "metadata": {
        "id": "TI_WeGeiZMM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import requests\n",
        "import time\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import regex\n",
        "import tensorflow as tf\n",
        "import threading\n",
        "from bs4 import BeautifulSoup\n",
        "from pytz import timezone\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "from unidecode import unidecode\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from xgboost import XGBRegressor\n",
        "import xgboost as xgb\n",
        "\n",
        "import model\n",
        "import evaluator\n",
        "import date\n",
        "import box_score\n",
        "import helper_functions\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "eta = 0.1\n",
        "cost_threshold = 0.5\n",
        "expert_names = ['optimizer_preds', 'mlp_preds', 'dnn_preds', 'xgb_preds', 'lstm_preds', 'rf_preds']\n",
        "num_experts = len(expert_names)\n",
        "window_size = 10\n",
        "past_x_games = 5\n",
        "directory = '/NBA_Betting_Model/2023-24_Season/NBA-Bets-Multiplicative-Weights/' #directory to be changed\n",
        "file_suffixes = ['Pts', 'Ast', 'trb', 'Pts+Ast', 'Pts+Rebs', 'Rebs+Ast', 'Pts+Rebs+Ast',\n",
        "                 'Stl', 'Blk', 'Stl+Blk', 'fg3']\n",
        "stats_dict = {\n",
        "    'Pts': ['pts', 'fg3', 'ts_pct', 'efg_pct', 'fg3a_per_fga_pct', 'usg_pct', 'off_rtg', 'bpm', 'mp'],\n",
        "    'Ast': ['ast', 'ast_pct', 'usg_pct', 'off_rtg', 'bpm', 'mp'],\n",
        "    'Rebs': ['trb', 'orb_pct', 'drb_pct', 'trb_pct', 'usg_pct', 'off_rtg', 'bpm', 'mp'],\n",
        "    'Stl': ['stl', 'stl_pct', 'def_rtg', 'bpm', 'mp'],\n",
        "    'Blk': ['blk', 'blk_pct', 'def_rtg', 'bpm', 'mp'],\n",
        "    '3pt M': ['fg3', 'pts', 'ts_pct', 'efg_pct', 'fg3a_per_fga_pct', 'usg_pct', 'off_rtg', 'bpm', 'mp']\n",
        "}\n",
        "combo_stats = ['Pts+Ast', 'Pts+Rebs', 'Rebs+Ast', 'Pts+Rebs+Ast', 'Stl+Blk']\n",
        "models = [\"DNN\", \"MLP\", \"RF\", \"XGB\", \"LSTM\"]\n",
        "\n",
        "start_date = datetime.date(2023, 10, 1)\n",
        "end_date = datetime.date(2024, 6, 30)\n",
        "date_range = [start_date + datetime.timedelta(days=x) for x in range((end_date - start_date).days + 1)]\n",
        "\n",
        "month_ends = {}\n",
        "for date in date_range:\n",
        "    month = date.month\n",
        "    last_day = date.strftime('%d')\n",
        "    if month < 10:\n",
        "        month_ends[month] = int(str(month) + ('0' * (4 + (month - 1))) + str(int(last_day)))\n",
        "    else:\n",
        "        month_ends[month] = int(str(month) + last_day)\n",
        "month_order = [10, 11, 12, 1, 2, 3, 4, 5, 6]\n",
        "month_ends"
      ],
      "metadata": {
        "id": "FdcRde_yZbgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_files(directory, suffixes, prefix):\n",
        "    data = {}\n",
        "    for suffix in suffixes:\n",
        "        with open(f'{directory}{prefix}{suffix}.pkl', 'rb') as f:\n",
        "            data[suffix] = pickle.load(f)\n",
        "    return data\n",
        "\n",
        "import date\n",
        "date_tracker = date.Date()\n",
        "directory_month, directory_day = date_tracker.date_month_day(-2)\n",
        "month, day = date_tracker.date_month_day(-1)\n",
        "boxscore_month, boxscore_day = month, day\n",
        "directory_base = f'{directory}{directory_month}/{directory_day}/'\n",
        "expert_weights = load_files(directory_base, file_suffixes, 'expert_weights_')\n",
        "expert_history = load_files(directory_base, file_suffixes, 'expert_history_')\n",
        "date_counter = int(day) +1\n",
        "month_order = month_order[month_order.index(int(month)):]\n",
        "month = int(month)\n",
        "last_day = 31\n",
        "if month == 2:\n",
        "    last_day = 28\n",
        "elif month == 4 or month == 6:\n",
        "    last_day = 30\n",
        "if date_counter == 1:\n",
        "    if month == 11:\n",
        "        date_counter2 = month_ends[10]\n",
        "    if month == 12:\n",
        "        date_counter2 = month_ends[11]\n",
        "    elif month == 1:\n",
        "        date_counter2 = month_ends[12]\n",
        "    else:\n",
        "        date_counter2 = month_ends[month - 1]\n",
        "else:\n",
        "    if date_counter - 1 < 10:\n",
        "        if month == 10:\n",
        "            date_counter2 = int(str(100) + str(date_counter - 1))\n",
        "        elif month == 11:\n",
        "            date_counter2 = int(str(110) + str(date_counter - 1))\n",
        "        elif month == 12:\n",
        "            date_counter2 = int(str(120) + str(date_counter - 1))\n",
        "        else:\n",
        "            if date_counter - 1 == 9:\n",
        "                date_counter2 = int(str(month) + ('0' * (5 + (month - 1))) + str(date_counter - 1))\n",
        "            else:\n",
        "                date_counter2 = int(str(month) + ('0' * (4 + (month - 1))) + str(date_counter - 1))\n",
        "    else:\n",
        "        if month == 10:\n",
        "            date_counter2 = int(str(10) + str(date_counter - 1))\n",
        "        elif month == 11:\n",
        "            date_counter2 = int(str(11) + str(date_counter - 1))\n",
        "        elif month == 12:\n",
        "            date_counter2 = int(str(12) + str(date_counter - 1))\n",
        "        else:\n",
        "            date_counter2 = int(str(month) + ('0' * (4 + (month - 1))) + str(date_counter - 1))\n",
        "date_counter -= 1\n",
        "month_folder = os.path.join(directory, str(month))\n",
        "if not os.path.exists(month_folder):\n",
        "    os.makedirs(month_folder)\n",
        "day_folder = os.path.join(month_folder, str(date_counter))\n",
        "if not os.path.exists(day_folder):\n",
        "    os.makedirs(day_folder)\n",
        "model_predictions_dict = {}\n",
        "if int(date_counter) < 10:\n",
        "    date_counter = '0' + str(date_counter)"
      ],
      "metadata": {
        "id": "l-4nmsNDl38U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "month, date_counter, date_counter2"
      ],
      "metadata": {
        "id": "-oPRyEf2pLBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "all box scores before yesterday"
      ],
      "metadata": {
        "id": "fW4D3pxSl5Xf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "from datetime import datetime\n",
        "from datetime import timedelta\n",
        "date_format = '%m/%d/%Y %H:%M:%S %Z'\n",
        "date = datetime.now(timezone('US/Pacific'))\n",
        "date = date.astimezone(timezone('US/Pacific'))\n",
        "today_date = date.strftime(date_format)\n",
        "today = today_date.split('/')[0] + '/' + date.strftime(date_format).split('/')[1]\n",
        "today_date = today_date.split(' ')[0]\n",
        "month_name = datetime.strptime(today.split('/')[0].strip(), \"%m\").strftime(\"%B\").lower()\n",
        "month = today.split('/')[0]\n",
        "day = today.split('/')[1]\n",
        "action_date = month_name[:3].upper() + ' ' + day\n",
        "time_delta = timedelta(days=1)\n",
        "while not (month == '10' and day == '24'):\n",
        "    date -= time_delta\n",
        "    today_date = date.strftime(date_format)\n",
        "    today = today_date.split('/')[0] + '/' + date.strftime(date_format).split('/')[1]\n",
        "    month = today.split('/')[0]\n",
        "    day = today.split('/')[1]\n",
        "print(month, day)\n",
        "print('before allboxscores')\n",
        "all_box_score_results = pd.DataFrame()\n",
        "while not (month == boxscore_month and day == boxscore_day):\n",
        "    print(month, day)\n",
        "    if (month, day) in [('11', '07'), ('11', '23'), ('12', '03'), ('12', '10')]:\n",
        "        date += time_delta\n",
        "        today_date = date.strftime(date_format)\n",
        "        today = today_date.split('/')[0] + '/' + date.strftime(date_format).split('/')[1]\n",
        "        month = today.split('/')[0]\n",
        "        day = today.split('/')[1]\n",
        "        print(month, day)\n",
        "        continue\n",
        "    past_box_score = pd.read_csv(\"/NBA_Betting_Model/2023-24_Season/NBA-Bets-Box-Score-Results/\" + \"NBA-Bets-Box-Score-Results-\" + month + \"-\" + str(day.lstrip(\"0\")) +\".csv\")\n",
        "    past_box_score['date'] = month + \"-\" + day\n",
        "    past_box_score['name'] = past_box_score['name'].apply(unidecode)\n",
        "    past_box_score['name'] = past_box_score['name'].apply(helper_functions.abbrv)\n",
        "    past_box_score['date'] = past_box_score['date'].apply(date_tracker.date_converter)\n",
        "    all_box_score_results = all_box_score_results.append(past_box_score)\n",
        "    all_box_score_results = all_box_score_results.dropna(subset=['date'])\n",
        "\n",
        "    all_box_score_results['date'] = all_box_score_results['date'].astype('int')\n",
        "    all_box_score_results = all_box_score_results.sort_values(by=['date'], ascending = False)\n",
        "    all_box_score_results.set_index(['name','team']).index.factorize()[0]+1\n",
        "    all_box_score_results = all_box_score_results.drop_duplicates(['date','name','team', 'opp', 'hmcrt_adv', 'pts', 'ast', 'trb'], keep='last')\n",
        "    date += time_delta\n",
        "    today_date = date.strftime(date_format)\n",
        "    today = today_date.split('/')[0] + '/' + date.strftime(date_format).split('/')[1]\n",
        "    month = today.split('/')[0]\n",
        "    day = today.split('/')[1]\n",
        "\n",
        "all_box_score_results"
      ],
      "metadata": {
        "id": "IucCcHD4l4gT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yesterday's Box Score"
      ],
      "metadata": {
        "id": "XH0vkUSvaTwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#extract yesterday's games statistics and add to cumulative statistics history\n",
        "box_score = box_score.BoxScore()\n",
        "box_score_result = box_score.full_box_scores(str(boxscore_month), str(boxscore_day))\n",
        "box_score_result['date'] = boxscore_month + \"-\" + boxscore_day\n",
        "print(boxscore_month + \"-\" + boxscore_day)\n",
        "box_score_result['name'] = box_score_result['name'].apply(unidecode)\n",
        "box_score_result['name'] = box_score_result['name'].apply(helper_functions.abbrv)\n",
        "box_score_result['date'] = box_score_result['date'].apply(date_tracker.date_converter)\n",
        "box_score_result"
      ],
      "metadata": {
        "id": "REB4hh2faWzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boxscore_month, boxscore_day"
      ],
      "metadata": {
        "id": "bbjAlCgoqTJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "box_score_result.to_csv(\"/NBA_Betting_Model/2023-24_Season/NBA-Bets-Box-Score-Results/\" + \"NBA-Bets-Box-Score-Results-\" + boxscore_month + \"-\" + str(boxscore_day.lstrip(\"0\")) +\".csv\")\n",
        "\n",
        "predictions = pd.read_csv('/NBA_Betting_Model/2023-24_Season/NBA-Bets-Predictions/NBA-Bets-' + str(boxscore_month) + '-' + str(boxscore_day) + '.csv')\n",
        "predictions"
      ],
      "metadata": {
        "id": "OYij6sg1adP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate Yesterday's predictions"
      ],
      "metadata": {
        "id": "xKIUHcLBapZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluations = evaluator.Evaluator()\n",
        "evaluated_predictions = evaluations.predictions_evaluator(predictions, box_score_result)\n",
        "columns_to_update = ['All Game Percentages', 'All Game Correct', 'Last 5 Percentages', 'Last 5 Correct', 'Last 10 Percentages', 'Last 10 Correct']\n",
        "predictions_subset = predictions[columns_to_update]\n",
        "evaluated_predictions.update(predictions_subset)\n",
        "evaluated_predictions"
      ],
      "metadata": {
        "id": "EoBdGF95aq-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluated_predictions.to_csv('/NBA_Betting_Model/2023-24_Season/NBA-Bets-Evaluations/NBA-Bets-Evaluations-' + str(boxscore_month) + '-' + str(boxscore_day) + '.csv')\n"
      ],
      "metadata": {
        "id": "WTNV47m5avxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_box_score_results_past_eval = all_box_score_results[all_box_score_results['mp'] > 1]\n",
        "all_box_score_results_past_eval.insert(loc=0, column='player_id', value = all_box_score_results_past_eval.set_index(['name','team']).index.factorize()[0]+1)\n",
        "all_box_score_results_past_eval = all_box_score_results_past_eval.sort_values(by = ['date', 'player_id'], ascending = [True, True])\n",
        "all_box_score_results_past_eval"
      ],
      "metadata": {
        "id": "VszwXgZNmwTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prop_type_conversion(prop_type):\n",
        "    conversions = {'Rebs': 'trb', '3pt M': 'fg3'}\n",
        "    return conversions.get(prop_type, prop_type)\n",
        "\n",
        "def eval_past(folder_path, month, date_counter, prop_type, intersection, combined):\n",
        "    past_eval = pd.read_csv('/NBA_Betting_Model/2023-24_Season/NBA-Bets-Evaluations/NBA-Bets-Evaluations-' + str(month) + '-' + str(date_counter) + '.csv')\n",
        "    if prop_type == 'trb':\n",
        "        prop_type = 'Rebs'\n",
        "    if prop_type == 'fg3':\n",
        "        prop_type = '3pt M'\n",
        "    past_eval = past_eval.loc[past_eval['Play'].str.contains(prop_type, regex=False)]\n",
        "    if '+' not in prop_type:\n",
        "        past_eval = past_eval.loc[~past_eval['Play'].str.contains(r'\\+')]\n",
        "    if prop_type == 'Rebs+Ast':\n",
        "        past_eval = past_eval.loc[~past_eval['Play'].str.contains('Pts')]\n",
        "    elif prop_type == 'Pts+Rebs':\n",
        "        past_eval = past_eval.loc[~past_eval['Play'].str.contains('Ast')]\n",
        "    if not os.path.exists(folder_path + '/evals'):\n",
        "        os.makedirs(folder_path + '/evals')\n",
        "    unnamed_columns_past_eval = [col for col in past_eval.columns if col.startswith('Unnamed:')]\n",
        "    past_eval = past_eval.drop(columns=unnamed_columns_past_eval)\n",
        "    int_columns = ['Odds', 'Hmcrt_adv', 'All Game Correct', 'Last 5 Correct', 'Last 10 Correct']\n",
        "    float_columns = ['Units', 'Payout', 'Profit', 'All Game Percentages', 'Last 5 Percentages', 'Last 10 Percentages']\n",
        "    past_eval[int_columns] = past_eval[int_columns].apply(pd.to_numeric, errors='coerce')\n",
        "    past_eval[float_columns] = past_eval[float_columns].astype(float)\n",
        "    intersection_eval = pd.merge(intersection, past_eval)\n",
        "    intersection_eval.to_csv(folder_path + '/evals/' + 'intersection_eval_' + str(prop_type) + '.csv')\n",
        "    float_columns = ['Units', 'Payout', 'Profit', 'All Game Percentages', 'Last 5 Percentages', 'Last 10 Percentages', 'All Game Correct', 'Last 5 Correct', 'Last 10 Correct']\n",
        "    past_eval[float_columns] = past_eval[float_columns].astype(float)\n",
        "    combined_eval = pd.merge(combined, past_eval)\n",
        "    combined_eval.to_csv(folder_path + '/evals/' + 'combined_eval_' + str(prop_type) + '.csv')\n",
        "    return [1 if val == 'Y' else 0 for val in past_eval['Correct'].values]\n",
        "\n",
        "def weighted_experts(expert_weights, expert_history, cost_threshold, num_experts, window_size, eta, all_preds, true_labels):\n",
        "    decay_rate = 0.9\n",
        "    for i in range(len(true_labels)):\n",
        "        true_label = true_labels[i]\n",
        "        expert_predictions = [preds[i] for preds in all_preds]\n",
        "        weighted_predictions = expert_weights * expert_predictions\n",
        "        total_weighted_prediction = np.sum(weighted_predictions)\n",
        "        final_prediction = 1 if total_weighted_prediction > cost_threshold else 0\n",
        "        for j in range(num_experts):\n",
        "            expert_error = abs(expert_predictions[j] - true_label)\n",
        "            expert_history[j, i % window_size] = expert_error\n",
        "            decayed_eta = eta * (decay_rate ** i)\n",
        "            expert_weights[j] *= np.exp(-decayed_eta * expert_error)\n",
        "        expert_weights /= np.sum(expert_weights)\n",
        "    return expert_weights\n",
        "\n",
        "def prop_evaluation_with_experts(folder_path, month, date_counter, date_counter2, prop_type, features_set, past_data, past_x_games, expert_names, expert_weights_diff, expert_history_diff, cost_threshold, num_experts, window_size, eta, intersection, combined, passed_in_data1=None):\n",
        "    prop_type = prop_type_conversion(prop_type)\n",
        "    print('this is prop type')\n",
        "    print(prop_type)\n",
        "    pickle_path = os.path.join(folder_path, f'all_preds_{prop_type}.pkl')\n",
        "    if os.path.exists(pickle_path):\n",
        "        with open(pickle_path, 'rb') as f:\n",
        "            all_preds = pickle.load(f)\n",
        "    else:\n",
        "        all_preds = None\n",
        "    if all_preds:\n",
        "        true_labels = eval_past(folder_path, month, date_counter, prop_type, intersection, combined)\n",
        "        print(true_labels)\n",
        "        expert_weights_diff = weighted_experts(expert_weights_diff, expert_history_diff, cost_threshold, num_experts, window_size, eta, all_preds, true_labels)\n",
        "    else:\n",
        "        expert_weights_diff = expert_weights_diff\n",
        "    with open(os.path.join(folder_path, f'expert_weights_{prop_type}.pkl'), 'wb') as f:\n",
        "        pickle.dump(expert_weights_diff, f)\n",
        "    with open(os.path.join(folder_path, f'expert_history_{prop_type}.pkl'), 'wb') as f:\n",
        "        pickle.dump(expert_history_diff, f)\n",
        "    return expert_weights_diff, expert_history_diff\n",
        "\n",
        "optimizations_folder_path = day_folder + '/optimizations'\n",
        "final_combined_df = pd.read_csv(optimizations_folder_path + '/final_combined.csv')\n",
        "final_intersection_df = pd.read_csv(optimizations_folder_path + '/final_intersection.csv')\n",
        "\n",
        "for stat, attributes in stats_dict.items():\n",
        "    if stat == 'Rebs':\n",
        "        file_stat = 'trb'\n",
        "    elif stat == '3pt M':\n",
        "        file_stat = 'fg3'\n",
        "    else:\n",
        "        file_stat = stat\n",
        "    expert_weights[stat], expert_history[stat] = prop_evaluation_with_experts(\n",
        "        day_folder, month, date_counter, date_counter2, stat, attributes, all_box_score_results, past_x_games, expert_names,\n",
        "        expert_weights[file_stat], expert_history[file_stat], cost_threshold, num_experts, window_size, eta, final_intersection_df, final_combined_df\n",
        "    )\n",
        "\n",
        "for combo in combo_stats:\n",
        "    stats = [stat if stat != 'Rebs' else 'trb' for stat in combo.split('+')]\n",
        "    expert_weights[combo], expert_history[combo] = prop_evaluation_with_experts(\n",
        "        day_folder, month, date_counter, date_counter2, combo, [], all_box_score_results, past_x_games, expert_names, expert_weights[combo],\n",
        "        expert_history[combo], cost_threshold, num_experts, window_size, eta, final_intersection_df, final_combined_df)\n"
      ],
      "metadata": {
        "id": "IYnlK6_naxv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evals_folder_path = day_folder + '/evals'\n",
        "final_combined_df_eval = pd.DataFrame()\n",
        "final_intersection_df_eval = pd.DataFrame()\n",
        "for file in os.listdir(evals_folder_path):\n",
        "    if file.startswith('combined_eval_'):\n",
        "        df = pd.read_csv(os.path.join(evals_folder_path, file))\n",
        "        final_combined_df_eval = pd.concat([final_combined_df_eval, df], ignore_index=True)\n",
        "    elif file.startswith('intersection_eval_'):\n",
        "        df = pd.read_csv(os.path.join(evals_folder_path, file))\n",
        "        final_intersection_df_eval = pd.concat([final_intersection_df_eval, df], ignore_index=True)\n",
        "\n",
        "unnamed_columns_final_combined_df_eval = [col for col in final_combined_df_eval.columns if col.startswith('Unnamed:')]\n",
        "final_combined_df_eval = final_combined_df_eval.drop(columns=unnamed_columns_final_combined_df_eval)\n",
        "final_combined_df_eval = final_combined_df_eval.drop_duplicates()\n",
        "unnamed_columns_final_intersection_df_eval = [col for col in final_intersection_df_eval.columns if col.startswith('Unnamed:')]\n",
        "final_intersection_df_eval = final_intersection_df_eval.drop(columns=unnamed_columns_final_intersection_df_eval)\n",
        "final_intersection_df_eval = final_intersection_df_eval.drop_duplicates()\n",
        "final_combined_df_eval.to_csv(evals_folder_path + '/final_combined_eval.csv', index=False)\n",
        "final_intersection_df_eval.to_csv(evals_folder_path + '/final_intersection_eval.csv', index=False)\n"
      ],
      "metadata": {
        "id": "RIFN5MHFoEKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_combined_df_eval"
      ],
      "metadata": {
        "id": "FmGaIm6LoKK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_intersection_df_eval"
      ],
      "metadata": {
        "id": "r_SjrXJyoLKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "past_eval = pd.read_csv('/NBA_Betting_Model/2023-24_Season/NBA-Bets-Evaluations/NBA-Bets-Evaluations-' + str(boxscore_month) + '-' + str(boxscore_day) + '.csv')\n",
        "past_eval"
      ],
      "metadata": {
        "id": "p12TjdohoIo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimized_curr = pd.read_csv('/NBA_Betting_Model/2023-24_Season/NBA-Bets-Optimized-Predictions/NBA-Optimized-Bets-' + str(boxscore_month) + '-' + str(boxscore_day) + '.csv')\n",
        "optimized_curr"
      ],
      "metadata": {
        "id": "RZ9c9RNsoOCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optimized_predictions_evaluator(optimized_predictions, current_evaluation):\n",
        "    #return evaluations of past optimized predictions\n",
        "    optimized_correct = []\n",
        "    for i in range(len(optimized_predictions)):\n",
        "        optimized_prediction = optimized_predictions.loc[i]\n",
        "        if len(current_evaluation[(current_evaluation['Play'] == optimized_prediction['Play']) & (current_evaluation['Expert'] == optimized_prediction['Expert'])  & (current_evaluation['Odds'] == optimized_prediction['Odds'])]) == 0:\n",
        "            optimized_correct.append('X')\n",
        "        else:\n",
        "            optimized_correct.append(current_evaluation[(current_evaluation['Play'] == optimized_prediction['Play']) & (current_evaluation['Expert'] == optimized_prediction['Expert'])  & (current_evaluation['Odds'] == optimized_prediction['Odds'])]['Correct'].values[0])\n",
        "    return optimized_correct\n",
        "optimized_predictions_evaluator(optimized_curr, past_eval)\n",
        "optimized_evaluations = optimized_curr\n",
        "optimized_evaluations['Correct'] = optimized_predictions_evaluator(optimized_curr, past_eval)\n",
        "optimized_evaluations"
      ],
      "metadata": {
        "id": "XbNYsX7aoPRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimized_evaluations.to_csv(\"/NBA_Betting_Model/2023-24_Season/NBA-Bets-Optimized-Evaluations\" + \"NBA-Bets-Optimized-Evaluations-\" + boxscore_month + \"-\" + boxscore_day +\".csv\")"
      ],
      "metadata": {
        "id": "kX0_HlzQoPMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NEW BET"
      ],
      "metadata": {
        "id": "P063F7w5oUV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import date\n",
        "date_tracker = date.Date()\n",
        "month, day = date_tracker.date_month_day(0)\n",
        "date_counter = int(day) +1\n",
        "month_order = month_order[month_order.index(int(month)):]\n",
        "month = int(month)\n",
        "last_day = 31\n",
        "if month == 2:\n",
        "    last_day = 28\n",
        "elif month == 4 or month == 6:\n",
        "    last_day = 30\n",
        "if date_counter == 1:\n",
        "    if month == 11:\n",
        "        date_counter2 = month_ends[10]\n",
        "    if month == 12:\n",
        "        date_counter2 = month_ends[11]\n",
        "    elif month == 1:\n",
        "        date_counter2 = month_ends[12]\n",
        "    else:\n",
        "        date_counter2 = month_ends[month - 1]\n",
        "else:\n",
        "    if date_counter - 1 < 10:\n",
        "        if month == 10:\n",
        "            date_counter2 = int(str(100) + str(date_counter - 1))\n",
        "        elif month == 11:\n",
        "            date_counter2 = int(str(110) + str(date_counter - 1))\n",
        "        elif month == 12:\n",
        "            date_counter2 = int(str(120) + str(date_counter - 1))\n",
        "        else:\n",
        "            if date_counter - 1 == 9:\n",
        "                date_counter2 = int(str(month) + ('0' * (5 + (month - 1))) + str(date_counter - 1))\n",
        "            else:\n",
        "                date_counter2 = int(str(month) + ('0' * (4 + (month - 1))) + str(date_counter - 1))\n",
        "    else:\n",
        "        if month == 10:\n",
        "            date_counter2 = int(str(10) + str(date_counter - 1))\n",
        "        elif month == 11:\n",
        "            date_counter2 = int(str(11) + str(date_counter - 1))\n",
        "        elif month == 12:\n",
        "            date_counter2 = int(str(12) + str(date_counter - 1))\n",
        "        else:\n",
        "            date_counter2 = int(str(month) + ('0' * (4 + (month - 1))) + str(date_counter - 1))\n",
        "date_counter -= 1\n",
        "month_folder = os.path.join(directory, str(month))\n",
        "if not os.path.exists(month_folder):\n",
        "    os.makedirs(month_folder)\n",
        "day_folder = os.path.join(month_folder, str(date_counter))\n",
        "if not os.path.exists(day_folder):\n",
        "    os.makedirs(day_folder)\n",
        "model_predictions_dict = {}\n",
        "if int(date_counter) < 10:\n",
        "    date_counter = '0' + str(date_counter)\n",
        "month, date_counter, date_counter2"
      ],
      "metadata": {
        "id": "H7xIsioI-Hpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_modified_html(initial_html, updated_html):\n",
        "    initial_soup = BeautifulSoup(initial_html, \"html.parser\")\n",
        "    updated_soup = BeautifulSoup(updated_html, \"html.parser\")\n",
        "    modified_parts = []\n",
        "    for initial_tag, updated_tag in zip(initial_soup.find_all(), updated_soup.find_all()):\n",
        "        if str(initial_tag) != str(updated_tag):\n",
        "            modified_parts.append(updated_tag)\n",
        "    modified_html = '\\n'.join(str(tag) for tag in modified_parts)\n",
        "    return modified_html\n",
        "\n",
        "def click_with_retry(driver, entry, selector, max_attempts=5):\n",
        "    attempts = 0\n",
        "    while attempts < max_attempts:\n",
        "        try:\n",
        "            see_all_button = entry.find_element(By.CSS_SELECTOR, selector)\n",
        "            driver.execute_script(\"arguments[0].click();\", see_all_button)\n",
        "            return\n",
        "        except selenium.common.exceptions.StaleElementReferenceException:\n",
        "            attempts += 1\n",
        "            time.sleep(1)\n",
        "\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "chrome_options.add_argument('--disable-gpu')\n",
        "chrome_options.add_argument('--start-maximized')\n",
        "chrome_options.add_argument('--disable-infobars')\n",
        "chrome_options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
        "chrome_options.binary_location = \"/usr/bin/chromium-browser\"\n",
        "driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "import datetime\n",
        "from datetime import datetime\n",
        "from datetime import timedelta\n",
        "date_format = '%m/%d/%Y %H:%M:%S %Z'\n",
        "date = datetime.now(timezone('US/Pacific'))\n",
        "date = date.astimezone(timezone('US/Pacific'))\n",
        "today_date = date.strftime(date_format)\n",
        "today = today_date.split('/')[0] + '/' + date.strftime(date_format).split('/')[1]\n",
        "today_date = today_date.split(' ')[0]\n",
        "month_name = datetime.strptime(today.split('/')[0].strip(), \"%m\").strftime(\"%B\").lower()\n",
        "action_month = today.split('/')[0]\n",
        "action_day = today.split('/')[1]\n",
        "action_date = month_name[:3].upper() + ' ' + action_day\n",
        "action_month, action_day"
      ],
      "metadata": {
        "id": "FAq7XGbEoTtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prop_type_conversion(prop_type):\n",
        "    conversions = {'Rebs': 'trb', '3pt M': 'fg3'}\n",
        "    return conversions.get(prop_type, prop_type)\n",
        "\n",
        "def process_csv(filename, prop_type):\n",
        "    data = pd.read_csv(filename)\n",
        "    data = data.loc[data['Play'].str.contains(prop_type, regex=False)]\n",
        "    if '+' not in prop_type:\n",
        "        data = data.loc[~data['Play'].str.contains(r'\\+')]\n",
        "    if prop_type == 'Rebs+Ast':\n",
        "        data = data.loc[~data['Play'].str.contains('Pts')]\n",
        "    elif prop_type == 'Pts+Rebs':\n",
        "        data = data.loc[~data['Play'].str.contains('Ast')]\n",
        "    return data\n",
        "\n",
        "def weighted_optimizer(folder_path, expert_names, expert_weights, prop_type, all_predictions_dfs):\n",
        "    expert_to_df_map = {expert_name: all_predictions_dfs[i] for i, expert_name in enumerate(expert_names)}\n",
        "    if len(set(expert_weights)) == 1:\n",
        "        best_experts = random.sample(expert_names, 2)\n",
        "    else:\n",
        "        indices = np.array(expert_weights).argsort()[-2:][::-1]\n",
        "        best_experts = [expert_names[index] for index in indices]\n",
        "    major1 = expert_to_df_map[best_experts[0]]\n",
        "    major2 = expert_to_df_map[best_experts[1]]\n",
        "    if not os.path.exists(folder_path + '/optimizations'):\n",
        "        os.makedirs(folder_path + '/optimizations')\n",
        "    expert_to_df_map = {expert_name: df for expert_name, df in zip(expert_names, all_predictions_dfs)}\n",
        "    if len(set(expert_weights)) == 1:\n",
        "        best_experts = random.sample(expert_names, 2)\n",
        "    else:\n",
        "        indices = np.array(expert_weights).argsort()[-2:][::-1]\n",
        "        best_experts = [expert_names[index] for index in indices]\n",
        "    major1 = expert_to_df_map[best_experts[0]]\n",
        "    major2 = expert_to_df_map[best_experts[1]]\n",
        "    unnamed_columns_major1 = [col for col in major1.columns if col.startswith('Unnamed:')]\n",
        "    major1 = major1.drop(columns=unnamed_columns_major1)\n",
        "    unnamed_columns_major2 = [col for col in major2.columns if col.startswith('Unnamed:')]\n",
        "    major2 = major2.drop(columns=unnamed_columns_major2)\n",
        "    int_columns = ['Odds', 'Hmcrt_adv']\n",
        "    float_columns = ['Units', 'Payout', 'Profit']\n",
        "    major1[int_columns] = major1[int_columns].apply(pd.to_numeric, errors='coerce')\n",
        "    major1[float_columns] = major1[float_columns].astype(float)\n",
        "    major2[int_columns] = major2[int_columns].apply(pd.to_numeric, errors='coerce')\n",
        "    major2[float_columns] = major2[float_columns].astype(float)\n",
        "    intersection = pd.merge(major1, major2, how='inner').drop_duplicates()\n",
        "    intersection.to_csv(folder_path + '/optimizations/' + 'intersection_' + str(prop_type) + '.csv')\n",
        "    combined = pd.concat([major1, major2], axis=0).drop_duplicates()\n",
        "    combined.to_csv(folder_path + '/optimizations/' + 'combined_' + str(prop_type) + '.csv')\n",
        "    return intersection, combined\n",
        "\n",
        "def get_model_names_from_predictions(predictions, prop_type):\n",
        "    return [col.split('_')[1] for col in predictions.columns if f\"PlayerPredictions_\" in col and prop_type in col]\n",
        "\n",
        "def get_prediction(predictions, model_name, prop_type, player_name, team):\n",
        "    filtered_df = predictions[(predictions['PlayerName'] == player_name) &\n",
        "                              (predictions['PlayerTeam'] == team)]\n",
        "    if not filtered_df.empty:\n",
        "        return float(filtered_df[f'PlayerPredictions_{model_name}_{prop_type}'].values[0][0])\n",
        "    else:\n",
        "        return 0.0\n",
        "\n",
        "def models_predictions_eval(folder_path, predictions, optimized, unoptimized, prop_type):\n",
        "    model_names = get_model_names_from_predictions(predictions, prop_type)\n",
        "    preds_dict = {name: [] for name in model_names}\n",
        "    optimizer_preds = []\n",
        "    for play, team in zip(unoptimized['Play'].values, unoptimized['Teams'].values):\n",
        "        player_name = play.split(' ')[0]\n",
        "        bet_value = float(play.split(' ')[1][1:])\n",
        "        over_under = play.split(' ')[1][0]\n",
        "        if play not in optimized['Play'].values:\n",
        "            optimizer_preds.append(0)\n",
        "        else:\n",
        "            optimizer_preds.append(1)\n",
        "        for model_name in model_names:\n",
        "            prediction = get_prediction(predictions, model_name, prop_type, player_name, team)\n",
        "            is_over = int(prediction > bet_value)\n",
        "            is_under = int(prediction < bet_value)\n",
        "            preds_dict[model_name].append(is_over if over_under == 'o' else is_under)\n",
        "    prediction_path = os.path.join(folder_path, 'predictions')\n",
        "    if not os.path.exists(prediction_path):\n",
        "        os.makedirs(prediction_path)\n",
        "    predictions_df_dict = {}\n",
        "    for model_name in model_names:\n",
        "        predictions_df_dict[model_name] = unoptimized[[bool(x) for x in preds_dict[model_name]]]\n",
        "        predictions_df_dict[model_name].to_csv(os.path.join(prediction_path, f'{model_name}_{prop_type}.csv'))\n",
        "    all_preds = [optimizer_preds] + list(preds_dict.values())\n",
        "    all_predictions_dfs = [optimized] + list(predictions_df_dict.values())\n",
        "    return all_preds, all_predictions_dfs\n",
        "\n",
        "def preprocess_model(past_data, prop_type, features_set):\n",
        "    info_data = past_data[features_set]\n",
        "    info_data = info_data.dropna()\n",
        "    features = list(info_data.columns)\n",
        "    features.remove(prop_type.lower())\n",
        "    target = [prop_type.lower()]\n",
        "    X = info_data.loc[:, features].values\n",
        "    y = info_data.loc[:, target].values\n",
        "    return train_test_split(X, y, test_size=0.1, random_state=1)\n",
        "\n",
        "def train_model(model, X_train, y_train):\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "def predict_model(model, player_last_avgs, player_preds):\n",
        "    with open(os.devnull, 'w') as devnull:\n",
        "        # sys.stdout = devnull\n",
        "        player_pred = model.predict(player_last_avgs)\n",
        "        # sys.stdout = sys.__stdout__\n",
        "        player_preds.append(player_pred)\n",
        "\n",
        "def define_models(X_train, y_train):\n",
        "    normalizer = tf.keras.layers.Normalization(axis=-1)\n",
        "    normalizer.adapt(np.array(X_train))\n",
        "    model_defs = {\n",
        "        'DNN': Sequential([\n",
        "            normalizer,\n",
        "            Dense(128, activation='relu'),\n",
        "            Dense(128, activation='relu'),\n",
        "            Dense(1)\n",
        "        ]),\n",
        "        'MLP': MLPRegressor(hidden_layer_sizes=(100,), solver='adam', random_state=42, max_iter=5000),\n",
        "        'RF': RandomForestRegressor(n_estimators=200, random_state=42),\n",
        "        'XGB': XGBRegressor(objective='reg:squarederror', n_estimators=200, learning_rate=0.05,\n",
        "                            max_depth=8, subsample=0.9, colsample_bytree=0.9, random_state=42, verbosity=0),\n",
        "        'LSTM': Sequential([\n",
        "            LSTM(128, input_shape=(X_train.shape[1], 1)),\n",
        "            Dense(1)\n",
        "        ])\n",
        "    }\n",
        "    model_defs['DNN'].compile(loss='mean_absolute_error', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
        "    model_defs['LSTM'].compile(optimizer='adam', loss='mse')\n",
        "    threads = {name: threading.Thread(target=train_model, args=(model, X_train, y_train)) for name, model in model_defs.items()}\n",
        "    [thread.start() for thread in threads.values()]\n",
        "    [thread.join() for thread in threads.values()]\n",
        "    return model_defs\n",
        "\n",
        "def last_x_avgs(data, prop_type, features_set, x):\n",
        "    last_x_games = data[-x:]\n",
        "    last_x_stats = last_x_games[features_set].mean(axis=0).to_frame().T\n",
        "    last_x_stats = last_x_stats.drop(prop_type, axis=1)\n",
        "    return last_x_stats\n",
        "\n",
        "def models_eval(past_data, past_x_games, prop_type, features_set, trained_models):\n",
        "    player_data_list = []\n",
        "    player_preds = {name: [] for name in trained_models}\n",
        "    for i in past_data['player_id'].unique():\n",
        "        player_data = past_data[past_data['player_id'] == i].fillna(0)\n",
        "        player_last_avgs = last_x_avgs(player_data, prop_type.lower(), features_set, past_x_games)\n",
        "        player_data_list.append({\n",
        "            'PlayerName': player_data['name'].values[0],\n",
        "            'PlayerTeam': player_data['team'].values[0],\n",
        "            'PlayerLastAvgs': player_last_avgs\n",
        "        })\n",
        "    for pdata in player_data_list:\n",
        "        threads = {model_name: threading.Thread(target=predict_model, args=(model, pdata['PlayerLastAvgs'], player_preds[model_name]))\n",
        "                   for model_name, model in trained_models.items()}\n",
        "        [thread.start() for thread in threads.values()]\n",
        "        [thread.join() for thread in threads.values()]\n",
        "    predictions = pd.DataFrame({\n",
        "        'PlayerName': [pdata['PlayerName'] for pdata in player_data_list],\n",
        "        'PlayerTeam': [pdata['PlayerTeam'] for pdata in player_data_list],\n",
        "        **{f'PlayerPredictions_{name}_{prop_type}': preds for name, preds in player_preds.items()}\n",
        "    })\n",
        "    return predictions\n",
        "\n",
        "def prop_prediction_with_experts(folder_path, month, date_counter, date_counter2, prop_type, features_set, past_data, past_x_games, expert_names, expert_weights_diff, expert_history_diff, cost_threshold, num_experts, window_size, eta, passed_in_data1=None):\n",
        "    prop_type = prop_type_conversion(prop_type)\n",
        "    print('this is prop type')\n",
        "    print(prop_type)\n",
        "    if passed_in_data1 is not None:\n",
        "        models_predictions = passed_in_data1\n",
        "    elif '+' in prop_type:\n",
        "        models_predictions = passed_in_data1\n",
        "    else:\n",
        "        X_train, X_val, y_train, y_val = preprocess_model(past_data, prop_type, features_set)\n",
        "        trained_models = define_models(X_train.astype(float), y_train.astype(float))\n",
        "        models_predictions = models_eval(past_data, past_x_games, prop_type, features_set, trained_models)\n",
        "    return models_predictions\n",
        "\n",
        "for stat, attributes in stats_dict.items():\n",
        "    if stat == 'Rebs':\n",
        "        file_stat = 'trb'\n",
        "    elif stat == '3pt M':\n",
        "        file_stat = 'fg3'\n",
        "    else:\n",
        "        file_stat = stat\n",
        "    model_predictions_dict[stat] = prop_prediction_with_experts(\n",
        "        day_folder, month, date_counter, date_counter2, stat, attributes, all_box_score_results_past_eval, past_x_games, expert_names,\n",
        "        expert_weights[file_stat], expert_history[file_stat], cost_threshold, num_experts, window_size, eta\n",
        "    )\n",
        "key_mapping = {\n",
        "    'Rebs': 'trb',\n",
        "    '3pt M': 'fg3'\n",
        "}\n",
        "model_predictions_dict = {\n",
        "    key_mapping.get(key, key): value for key, value in model_predictions_dict.items()\n",
        "}\n",
        "for combo in combo_stats:\n",
        "    stats = [stat if stat != 'Rebs' else 'trb' for stat in combo.split('+')]\n",
        "    if all([not model_predictions_dict[stat].empty for stat in stats]):\n",
        "        merged_predictions = model_predictions_dict[stats[0]]\n",
        "        for stat in stats[1:]:\n",
        "            merged_predictions = pd.merge(merged_predictions, model_predictions_dict[stat], on=['PlayerName', 'PlayerTeam'], how='inner')\n",
        "        for model in models:\n",
        "            merged_predictions[f'PlayerPredictions_{model}_{combo}'] = sum([merged_predictions[f'PlayerPredictions_{model}_{stat}'] for stat in stats])\n",
        "        model_predictions_dict[combo] = prop_prediction_with_experts(\n",
        "            day_folder, month, date_counter, date_counter2, combo, [], all_box_score_results_past_eval, past_x_games, expert_names, expert_weights[combo],\n",
        "            expert_history[combo], cost_threshold, num_experts, window_size, eta, merged_predictions)"
      ],
      "metadata": {
        "id": "rDCcSp7tsNUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "matchups"
      ],
      "metadata": {
        "id": "gZFxSt-_sUDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def site_scrape_chrome(url):\n",
        "    chrome_options = Options()\n",
        "    chrome_options.add_argument('--headless')\n",
        "    chrome_options.add_argument('--no-sandbox')\n",
        "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "    chrome_options.add_argument('--disable-gpu')\n",
        "    chrome_options.add_argument('--start-maximized')\n",
        "    chrome_options.add_argument('--disable-infobars')\n",
        "    chrome_options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
        "    chrome_options.binary_location = \"/usr/bin/chromium-browser\"\n",
        "    driver = webdriver.Chrome(options=chrome_options)\n",
        "    tz_params = {'timezoneId': 'America/Los_Angeles'}\n",
        "    driver.execute_cdp_cmd('Emulation.setTimezoneOverride', tz_params)\n",
        "    driver.get(url)\n",
        "    time.sleep(5)\n",
        "    html = driver.page_source\n",
        "    soup = BeautifulSoup(html, \"html.parser\")\n",
        "    driver.close()\n",
        "    return soup\n",
        "\n",
        "if int(action_month) > 9:\n",
        "    if int(action_day) < 10:\n",
        "        soup = site_scrape_chrome('https://theathletic.com/nba/schedule/2023-' + action_month + '-' + action_day + '/')\n",
        "    else:\n",
        "        soup = site_scrape_chrome('https://theathletic.com/nba/schedule/2023-' + action_month + '-' + action_day + '/')\n",
        "else:\n",
        "    if int(action_day) < 10:\n",
        "        soup = site_scrape_chrome('https://theathletic.com/nba/schedule/2023-' + action_month + '-' + action_day + '/')\n",
        "    else:\n",
        "        soup = site_scrape_chrome('https://theathletic.com/nba/schedule/2023-' + action_month + '-' + action_day + '/')\n",
        "games = soup.select('tr.MuiTableRow-root .jss6')\n",
        "matchups = []\n",
        "if games:\n",
        "    for i in range(0, len(games), 2):\n",
        "        home_team = str(games[i]).split('>')[2].split('<')[0]\n",
        "        away_team = str(games[i+1]).split('>')[2].split('<')[0]\n",
        "        matchup = f\"{home_team} vs {away_team}\"\n",
        "        matchups.append(matchup)\n",
        "else:\n",
        "    for val in str(soup).split('@context\":\"http://www.schema.org\"')[1:]:\n",
        "        match = re.search(r'\"name\":\"([^\"]+ @ [^\"]+)\"', val)\n",
        "        if match:\n",
        "            matchup = match.group(1)\n",
        "            teams = matchup.split(' @ ')\n",
        "            if len(teams) == 2:\n",
        "                away_team, home_team = teams\n",
        "                matchup = f\"{home_team} vs {away_team}\"\n",
        "                matchups.append(matchup)\n",
        "            else:\n",
        "                break\n",
        "        else:\n",
        "            break\n",
        "matchups"
      ],
      "metadata": {
        "id": "XIstogESsVAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ACTION Bets"
      ],
      "metadata": {
        "id": "pROHHyqasMGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_payout(row):\n",
        "    odds = row['Odds']\n",
        "    units = row['Units']\n",
        "    if int(odds) > 0:\n",
        "        multiplier = (int(odds) / 100) + 1\n",
        "    else:\n",
        "        multiplier = (-100 / int(odds)) + 1\n",
        "    return float(float(multiplier) * float(units))\n",
        "tz_params = {'timezoneId': 'America/Los_Angeles'}\n",
        "driver.execute_cdp_cmd('Emulation.setTimezoneOverride', tz_params)\n",
        "driver.get('https://www.actionnetwork.com/nba/picks')\n",
        "time.sleep(5)\n",
        "initial_html = driver.page_source\n",
        "modified_htmls = []\n",
        "entries = driver.find_elements(By.CSS_SELECTOR, '.css-1pfshtc.e11h3jb20')\n",
        "for entry in entries:\n",
        "    see_all_button = entry.find_element(By.CSS_SELECTOR, 'button[data-testid=\"expert-picks__see-all-picks\"]')\n",
        "    click_with_retry(driver, entry, 'button[data-testid=\"expert-picks__see-all-picks\"]')\n",
        "    time.sleep(5)\n",
        "    updated_html = driver.page_source\n",
        "    modified_html = get_modified_html(initial_html, updated_html)\n",
        "    modified_htmls.append(modified_html)\n",
        "play_list, expert_list, odds_list, units_list, name_list = [], [], [], [], []\n",
        "site_data = modified_htmls\n",
        "for html in site_data:\n",
        "    for picks in str(html).split('Player Props')[1].split('<div class=\"pick-card__header\">')[1:]:\n",
        "        soup = BeautifulSoup(picks, 'html.parser')\n",
        "        play_elements = soup.select('.base-pick__name')\n",
        "        odds_elements = soup.select('.base-pick__secondary-text')\n",
        "        units_elements = soup.select('.base-pick__units')\n",
        "        expert_element = soup.select_one('.pick-card__expert-info > a')\n",
        "        if expert_element:\n",
        "            expert = expert_element['href'].split('/')[-1]\n",
        "        else:\n",
        "            expert = ''\n",
        "        for play_element, odds_element, units_element in zip(play_elements, odds_elements, units_elements):\n",
        "            if re.match(r'[A-Z]\\.[A-Za-z]+ [ou][\\d]+\\.[\\d] [A-Za-z]+', play_element.text):\n",
        "                play_list.append(play_element.text)\n",
        "                expert_list.append(expert)\n",
        "                odds_list.append(odds_element.text if odds_element else '')\n",
        "                units_list.append(units_element.text.split('u')[0] if units_element else '')\n",
        "                name_list.append(str(play_element.text).split(' ')[0])\n",
        "data = {\n",
        "    'Play': play_list,\n",
        "    'Expert': expert_list,\n",
        "    'Odds': odds_list,\n",
        "    'Units': units_list,\n",
        "    'Name': name_list\n",
        "}\n",
        "bets = pd.DataFrame(data)\n",
        "bets.to_csv(\"/NBA_Betting_Model/2023-24_Season/NBA-Bets-Predictions/\" + \"NBA-Bets-\" + str(action_month) + '-' + str(action_day) + '.csv')\n",
        "bets = bets[~bets['Play'].str.contains('TOs', na=False)]\n",
        "bets = bets[~bets['Play'].str.contains('(Live)', na=False)]\n",
        "bets = bets.reset_index(drop=True)\n",
        "\n",
        "all_box_score_results_for_predictions = all_box_score_results.sort_values(by='date', ascending=False)\n",
        "\n",
        "names, set_teams, opponents, hmcrt_advantages = [], [], [], []\n",
        "all_teams = set(all_box_score_results_for_predictions['team'].values)\n",
        "for i in range(len(bets)):\n",
        "    bet = bets.loc[i]\n",
        "    name = bet['Name'].split(' ')[0]\n",
        "    matching_name = all_box_score_results_for_predictions[all_box_score_results_for_predictions['name'] == name]\n",
        "    if len(set(matching_name['name'].values)) > 1:\n",
        "        set_teams.append('')\n",
        "        names.append(np.NAN)\n",
        "        opponents.append(np.NAN)\n",
        "        hmcrt_advantages.append(np.NAN)\n",
        "    elif len(set(matching_name['name'].values)) < 1:\n",
        "        print('less than 1')\n",
        "        set_teams.append('')\n",
        "        names.append(np.NAN)\n",
        "        opponents.append(np.NAN)\n",
        "        hmcrt_advantages.append(np.NAN)\n",
        "    else:\n",
        "        #gets most recent team regardless\n",
        "        team = matching_name.iloc[0]['team']\n",
        "        found_today = False\n",
        "        for matchup in matchups:\n",
        "            matchup_home = matchup.split('vs')[0].strip()\n",
        "            matchup_away = matchup.split('vs')[1].strip()\n",
        "            if matchup_home in team:\n",
        "                set_teams.append(team)\n",
        "                names.append(name)\n",
        "                for t in all_teams:\n",
        "                    if matchup_away in t:\n",
        "                        opponents.append(t)\n",
        "                        break\n",
        "                hmcrt_advantages.append(1)\n",
        "                found_today = True\n",
        "                break\n",
        "            elif matchup_away in team:\n",
        "                set_teams.append(team)\n",
        "                names.append(name)\n",
        "                for t in all_teams:\n",
        "                    if matchup_home in t:\n",
        "                        opponents.append(t)\n",
        "                        break\n",
        "                hmcrt_advantages.append(0)\n",
        "                found_today = True\n",
        "                break\n",
        "        if found_today:\n",
        "            continue\n",
        "        else:\n",
        "            set_teams.append('')\n",
        "            names.append(np.NAN)\n",
        "            opponents.append(np.NAN)\n",
        "            hmcrt_advantages.append(np.NAN)\n",
        "bets['Name'] = names\n",
        "bets['Teams'] = set_teams\n",
        "bets['Opponent'] = opponents\n",
        "bets['Hmcrt_adv'] = hmcrt_advantages\n",
        "bets['Payout'] = bets.apply(calculate_payout, axis=1)\n",
        "bets['Payout'] = bets['Payout'].astype(float)\n",
        "bets['Units'] = bets['Units'].astype(float)\n",
        "bets['Profit'] = bets['Payout'] - bets['Units']\n",
        "bets = bets[bets['Name'].notna()]\n",
        "bets = bets.drop_duplicates(subset=['Play', 'Expert'], keep='first').reset_index(drop=True)\n",
        "bets"
      ],
      "metadata": {
        "id": "hKH-Smz4oUBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def all_evaluations_func(cur_month, cur_day):\n",
        "    #return cumulative evaluations\n",
        "    all_evals = pd.DataFrame()\n",
        "    import datetime\n",
        "    from datetime import datetime\n",
        "    from datetime import timedelta\n",
        "    date_format = '%m/%d/%Y %H:%M:%S %Z'\n",
        "    date = datetime.now(timezone('US/Pacific'))\n",
        "    date = date.astimezone(timezone('US/Pacific'))\n",
        "    today_date = date.strftime(date_format)\n",
        "    today = today_date.split('/')[0] + '/' + date.strftime(date_format).split('/')[1]\n",
        "    today_date = today_date.split(' ')[0]\n",
        "    month_name = datetime.strptime(today.split('/')[0].strip(), \"%m\").strftime(\"%B\").lower()\n",
        "    month = today.split('/')[0]\n",
        "    day = today.split('/')[1]\n",
        "    action_date = month_name[:3].upper() + ' ' + day\n",
        "    time_delta = timedelta(days=1)\n",
        "    while not (month == '10' and day == '24'):\n",
        "        date -= time_delta\n",
        "        today_date = date.strftime(date_format)\n",
        "        today = today_date.split('/')[0] + '/' + date.strftime(date_format).split('/')[1]\n",
        "        month = today.split('/')[0]\n",
        "        day = today.split('/')[1]\n",
        "    print(month, day)\n",
        "    print('before allevals')\n",
        "    while not (month == cur_month and day == cur_day):\n",
        "        if (month, day) in [('11', '07'), ('11', '23'), ('12', '03'), ('12', '10'), ('12', '24')]:\n",
        "          date += time_delta\n",
        "          today_date = date.strftime(date_format)\n",
        "          today = today_date.split('/')[0] + '/' + date.strftime(date_format).split('/')[1]\n",
        "          month = today.split('/')[0]\n",
        "          day = today.split('/')[1]\n",
        "          print(month, day)\n",
        "          continue\n",
        "        eval_ = pd.read_csv(\"/NBA_Betting_Model/2023-24_Season/NBA-Bets-Evaluations/\" + \"NBA-Bets-Evaluations-\" + month + \"-\" + str(day) +\".csv\")\n",
        "        all_evals = all_evals.append(eval_)\n",
        "        date += time_delta\n",
        "        today_date = date.strftime(date_format)\n",
        "        today = today_date.split('/')[0] + '/' + date.strftime(date_format).split('/')[1]\n",
        "        month = today.split('/')[0]\n",
        "        day = today.split('/')[1]\n",
        "        print(month, day)\n",
        "    print('broke')\n",
        "    print(month, day)\n",
        "    return all_evals\n",
        "\n",
        "import model\n",
        "model = model.Model()\n",
        "import evaluator\n",
        "evaluations = evaluator.Evaluator()\n",
        "all_evaluations = all_evaluations_func(str(action_month), str(action_day))\n",
        "all_evaluations = all_evaluations.rename(columns={'Opponent': 'opponent', 'Name': 'name'})\n",
        "all_evaluations = model.preprocessing(all_evaluations, True)\n",
        "all_evaluations\n"
      ],
      "metadata": {
        "id": "6dL0uULg7T4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_box_score_results_for_evaluations = all_box_score_results_for_predictions\n",
        "unoptimized = bets\n",
        "bets_inputs = evaluations.past_games_trends(unoptimized, all_box_score_results_for_evaluations, False)\n",
        "unoptimized.to_csv(f'/NBA_Betting_Model/2023-24_Season/NBA-Bets-Predictions/NBA-Bets-{action_month}-{action_day}.csv')"
      ],
      "metadata": {
        "id": "XZswhebd7VbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generating the optimized predictions parts now\n",
        "bets_inputs = bets_inputs.rename(columns={'Opponent': 'opponent', 'Name': 'name'})\n",
        "bets_inputs = model.preprocessing(bets_inputs, False)\n",
        "features = model.features_processing(list(all_evaluations.columns[:len(all_evaluations.columns) - 1])[5:])\n",
        "features = [item for item in features if \"Unnamed\" not in item]\n",
        "target = [all_evaluations.columns[-1]]\n",
        "X, Y, final_model = model.train(features, target, all_evaluations)\n",
        "final_model.fit(X, Y)\n",
        "for i in set(features).difference(set(bets_inputs.columns[:len(bets_inputs.columns) - 1])):\n",
        "    bets_inputs[i] = 0\n",
        "\n",
        "#model predicts to optimize from today's set of predictions\n",
        "X_predictions = bets_inputs.loc[:, features].values\n",
        "predictions = final_model.predict(X_predictions)\n",
        "indices = [i for i in range(len(predictions)) if predictions[i] == 'Y']\n",
        "unoptimized.iloc[indices, :]"
      ],
      "metadata": {
        "id": "CMMXbIj-s-zj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimized_file_path = f'/NBA_Betting_Model/2023-24_Season/NBA-Bets-Optimized-Predictions/NBA-Optimized-Bets-{action_month}-{action_day}.csv'\n",
        "unoptimized.iloc[indices, :].to_csv(optimized_file_path)"
      ],
      "metadata": {
        "id": "kjO6Au1DtBYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "action_month, action_day"
      ],
      "metadata": {
        "id": "dewNGIOb8flE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "day_folder"
      ],
      "metadata": {
        "id": "PYN0UtY68xlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prop_prediction_with_experts_eval(folder_path, month, date_counter, prop_type, expert_weights_diff, models_predictions):\n",
        "    unoptimized = process_csv(f'/NBA_Betting_Model/2023-24_Season/NBA-Bets-Predictions/NBA-Bets-{month}-{date_counter}.csv', prop_type)\n",
        "    optimized = process_csv(f'/NBA_Betting_Model/2023-24_Season/NBA-Bets-Optimized-Predictions/NBA-Optimized-Bets-{month}-{date_counter}.csv', prop_type)\n",
        "    prop_type = prop_type_conversion(prop_type)\n",
        "    print('this is prop type')\n",
        "    print(prop_type)\n",
        "    all_preds = None\n",
        "    all_preds, all_predictions_dfs = models_predictions_eval(folder_path, models_predictions, optimized, unoptimized, prop_type)\n",
        "    all_empty = True\n",
        "    for df in all_predictions_dfs:\n",
        "        if not df.empty:\n",
        "            all_empty = False\n",
        "            break\n",
        "    if not all_empty:\n",
        "      intersection, combined = weighted_optimizer(folder_path, expert_names, expert_weights_diff, prop_type, all_predictions_dfs)\n",
        "      prop_type = prop_type.replace('\\\\', '')\n",
        "      if all_preds is not None:\n",
        "          with open(os.path.join(folder_path, f'all_preds_{prop_type}.pkl'), 'wb') as f:\n",
        "              pickle.dump(all_preds, f)\n",
        "    return models_predictions\n",
        "\n",
        "for stat, attributes in stats_dict.items():\n",
        "    if stat == 'Rebs':\n",
        "        file_stat = 'trb'\n",
        "    elif stat == '3pt M':\n",
        "        file_stat = 'fg3'\n",
        "    else:\n",
        "        file_stat = stat\n",
        "    model_predictions_dict[stat] = prop_prediction_with_experts_eval(\n",
        "        day_folder, action_month, action_day, stat, expert_weights[file_stat], model_predictions_dict[file_stat])\n",
        "model_predictions_dict = {\n",
        "    key_mapping.get(key, key): value for key, value in model_predictions_dict.items()\n",
        "}\n",
        "for combo in combo_stats:\n",
        "    stats = [stat if stat != 'Rebs' else 'trb' for stat in combo.split('+')]\n",
        "    if all([not model_predictions_dict[stat].empty for stat in stats]):\n",
        "        merged_predictions = model_predictions_dict[stats[0]]\n",
        "        for stat in stats[1:]:\n",
        "            merged_predictions = pd.merge(merged_predictions, model_predictions_dict[stat], on=['PlayerName', 'PlayerTeam'], how='inner')\n",
        "        for model in models:\n",
        "            merged_predictions[f'PlayerPredictions_{model}_{combo}'] = sum([merged_predictions[f'PlayerPredictions_{model}_{stat}'] for stat in stats])\n",
        "        model_predictions_dict[combo] = prop_prediction_with_experts_eval(\n",
        "        day_folder, action_month, action_day, combo, expert_weights[combo], model_predictions_dict[combo])\n",
        "\n",
        "optimizations_folder_path = day_folder + '/optimizations'\n",
        "final_combined_df = pd.DataFrame()\n",
        "final_intersection_df = pd.DataFrame()\n",
        "for file in os.listdir(optimizations_folder_path):\n",
        "    if file.startswith('combined_'):\n",
        "        df = pd.read_csv(os.path.join(optimizations_folder_path, file))\n",
        "        final_combined_df = pd.concat([final_combined_df, df], ignore_index=True)\n",
        "    elif file.startswith('intersection_'):\n",
        "        df = pd.read_csv(os.path.join(optimizations_folder_path, file))\n",
        "        final_intersection_df = pd.concat([final_intersection_df, df], ignore_index=True)\n",
        "final_combined_df = final_combined_df.drop_duplicates()\n",
        "final_intersection_df = final_intersection_df.drop_duplicates()\n",
        "final_combined_df.to_csv(optimizations_folder_path + '/final_combined.csv', index=False)\n",
        "final_intersection_df.to_csv(optimizations_folder_path + '/final_intersection.csv', index=False)"
      ],
      "metadata": {
        "id": "4GHnGbdbwQjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_combined_df"
      ],
      "metadata": {
        "id": "3eqX5BSfxY5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_intersection_df"
      ],
      "metadata": {
        "id": "aJG31YD4xauS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimized = unoptimized.iloc[indices, :]\n",
        "optimized"
      ],
      "metadata": {
        "id": "-KE0p3jx6XNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_combined_df = final_combined_df.loc[:, ~final_combined_df.columns.str.contains('Unnamed')]\n",
        "final_intersection_df = final_intersection_df.loc[:, ~final_intersection_df.columns.str.contains('Unnamed')]\n",
        "optimized = optimized.loc[:, ~optimized.columns.str.contains('Unnamed')]\n",
        "merge_columns = ['Play', 'Expert', 'Odds', 'Name', 'Teams', 'Opponent', 'Hmcrt_adv']\n",
        "for column in merge_columns:\n",
        "    final_combined_df[column] = final_combined_df[column].astype(str)\n",
        "    final_intersection_df[column] = final_intersection_df[column].astype(str)\n",
        "    optimized[column] = optimized[column].astype(str)\n",
        "overall_intersection_df = pd.merge(final_combined_df, final_intersection_df, on=merge_columns, how='inner')\n",
        "overall_intersection_df = pd.merge(overall_intersection_df, optimized, on=merge_columns, how='inner')\n",
        "overall_intersection_df_sorted_df = overall_intersection_df.sort_values(by='All Game Percentages', ascending=False)\n",
        "overall_intersection_df_sorted_df"
      ],
      "metadata": {
        "id": "HIuQEIra6ems"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}